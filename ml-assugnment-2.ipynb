{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:45:59.107697Z",
     "iopub.status.busy": "2025-03-15T11:45:59.107475Z",
     "iopub.status.idle": "2025-03-15T11:46:05.006406Z",
     "shell.execute_reply": "2025-03-15T11:46:05.005722Z",
     "shell.execute_reply.started": "2025-03-15T11:45:59.107677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "# Data processing libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Feature selection and extraction\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "\n",
    "# ML models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.008017Z",
     "iopub.status.busy": "2025-03-15T11:46:05.007317Z",
     "iopub.status.idle": "2025-03-15T11:46:05.584376Z",
     "shell.execute_reply": "2025-03-15T11:46:05.583478Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.007982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country   label  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country   label  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "        label  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[30162 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_synthetic_data(sample_data, n_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic data based on the sample to demonstrate the pipeline\n",
    "    \"\"\"\n",
    "    # Create a larger synthetic dataset based on the patterns in the samples\n",
    "    synth_data = pd.DataFrame(columns=sample_data.columns)\n",
    "    \n",
    "    # Get the numerical and categorical columns\n",
    "    numerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "    categorical_cols = [col for col in sample_data.columns if col not in numerical_cols and col != 'income']\n",
    "    \n",
    "    # Calculate statistics for numerical columns\n",
    "    num_stats = {col: (sample_data[col].mean(), sample_data[col].std()) for col in numerical_cols}\n",
    "    \n",
    "    # Get unique values for categorical columns\n",
    "    cat_values = {col: sample_data[col].unique() for col in categorical_cols}\n",
    "    \n",
    "    # Generate synthetic samples\n",
    "    synthetic_samples = []\n",
    "    \n",
    "    # Ensure class balance is closer to 75-25 (<=50K vs >50K)\n",
    "    for i in range(n_samples):\n",
    "        new_sample = {}\n",
    "        \n",
    "        # Generate numerical features with realistic distributions\n",
    "        for col in numerical_cols:\n",
    "            mean, std = num_stats[col]\n",
    "            new_sample[col] = max(0, int(np.random.normal(mean, std)))\n",
    "        \n",
    "        # Generate categorical features based on sample distribution\n",
    "        for col in categorical_cols:\n",
    "            new_sample[col] = np.random.choice(cat_values[col])\n",
    "        \n",
    "        # Assign label class - 75% <=50K, 25% >50K for demonstration\n",
    "        if i < 0.75 * n_samples:\n",
    "            new_sample['label'] = '<=50K'\n",
    "        else:\n",
    "            new_sample['label'] = '>50K'\n",
    "            \n",
    "            # Higher education, age, hours worked for >50K group\n",
    "            new_sample['education_num'] = max(12, new_sample['education_num'])\n",
    "            new_sample['age'] = max(30, new_sample['age'])\n",
    "            new_sample['hours_per_week'] = max(35, new_sample['hours_per_week'])\n",
    "            \n",
    "            # Higher capital gain probability\n",
    "            if np.random.random() > 0.7:\n",
    "                new_sample['capital-gain'] = np.random.randint(1000, 10000)\n",
    "        \n",
    "        synthetic_samples.append(new_sample)\n",
    "    \n",
    "    return pd.DataFrame(synthetic_samples)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the Adult dataset either from a URL or use a sample if URL not provided\n",
    "    \"\"\"\n",
    "    # For this implementation, we'll use the sample data provided\n",
    "    # In a real scenario, you would download from the URL\n",
    "    \n",
    "\n",
    "    # Define column names based on dataset description.\n",
    "    columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \n",
    "               \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "               \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"label\"]\n",
    "    \n",
    "    # Load dataset (treat \" ?\" as NA).\n",
    "    data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "                       header=None, names=columns, na_values=\" ?\")\n",
    "    \n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(data.head())\n",
    "    \n",
    "    # Correctly assign the column names\n",
    "    data.columns = columns\n",
    "    \n",
    "    # Display the first few rows to verify the changes\n",
    "    print(data.head())\n",
    "    \n",
    "    # Note: In an actual implementation, you'd use:\n",
    "    # data = pd.read_csv(file_url, names=columns)\n",
    "    \n",
    "    # For demonstration, let's create a synthetic expanded dataset based on the sample\n",
    "    # This will allow us to properly demonstrate all required techniques\n",
    "    \n",
    "    # expanded_data = generate_synthetic_data(data, 1000)  \n",
    "    \n",
    "    return data\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.586254Z",
     "iopub.status.busy": "2025-03-15T11:46:05.586020Z",
     "iopub.status.idle": "2025-03-15T11:46:05.591444Z",
     "shell.execute_reply": "2025-03-15T11:46:05.590662Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.586235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data splitting function \n",
    "def split_data(data, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split data into train (70%), validation (10%), and test (20%) sets\n",
    "    \"\"\"\n",
    "    # First split: 80% train+val, 20% test\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.592854Z",
     "iopub.status.busy": "2025-03-15T11:46:05.592600Z",
     "iopub.status.idle": "2025-03-15T11:46:05.613780Z",
     "shell.execute_reply": "2025-03-15T11:46:05.613012Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.592833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Preprocess the data: handle categorical features, missing values, scaling\n",
    "    \"\"\"\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after one-hot encoding\n",
    "    cat_feature_names = []\n",
    "    if categorical_cols:\n",
    "        encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    \n",
    "    feature_names = np.array(numerical_cols + list(cat_feature_names))\n",
    "    \n",
    "    return X_train_processed, X_test_processed, feature_names, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.614782Z",
     "iopub.status.busy": "2025-03-15T11:46:05.614539Z",
     "iopub.status.idle": "2025-03-15T11:46:05.633976Z",
     "shell.execute_reply": "2025-03-15T11:46:05.633163Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.614762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Part 1: Feature Selection Functions\n",
    "def mrmr_feature_selection(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Minimum Redundancy Maximum Relevance feature selection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to numpy arrays if not already\n",
    "        X_np = X if isinstance(X, np.ndarray) else X.to_numpy()\n",
    "        y_np = y if isinstance(y, np.ndarray) else y.to_numpy()\n",
    "        \n",
    "        # Label encode the target if it's categorical\n",
    "        if y_np.dtype == object or y_np.dtype.kind in ['U', 'S']:\n",
    "            le = LabelEncoder()\n",
    "            y_np = le.fit_transform(y_np)\n",
    "        \n",
    "        # Run MRMR\n",
    "        selected_features = MRMR.mrmr(X_np, y_np, n_selected_features=k)\n",
    "        \n",
    "        return selected_features\n",
    "    except Exception as e:\n",
    "        print(f\"MRMR feature selection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def select_k_best_features(X, y, k=10, score_func=f_classif):\n",
    "    \"\"\"\n",
    "    Select K best features based on statistical tests\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=score_func, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    \n",
    "    return selected_indices, X_new\n",
    "\n",
    "def recursive_feature_elimination(X, y, n_features=10):\n",
    "    \"\"\"\n",
    "    Recursive Feature Elimination using Random Forest\n",
    "    \"\"\"\n",
    "    estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    selector = RFE(estimator, n_features_to_select=n_features, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected_indices = np.where(selector.support_)[0]\n",
    "    \n",
    "    return selected_indices, selector.transform(X)\n",
    "\n",
    "# Part 1: Feature Extraction Function\n",
    "def apply_pca(X_train, X_test, n_components=None, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimensionality reduction\n",
    "    If n_components is None, select components to explain variance_threshold of variance\n",
    "    \"\"\"\n",
    "    if n_components is None:\n",
    "        # Start with all components\n",
    "        pca_full = PCA(random_state=42)\n",
    "        pca_full.fit(X_train)\n",
    "        \n",
    "        # Calculate cumulative explained variance\n",
    "        cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "        \n",
    "        # Find number of components needed to explain variance_threshold\n",
    "        n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "        print(f\"Selected {n_components} components to explain {variance_threshold*100:.1f}% of variance\")\n",
    "    \n",
    "    # Apply PCA with selected number of components\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    return X_train_pca, X_test_pca, pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.635093Z",
     "iopub.status.busy": "2025-03-15T11:46:05.634795Z",
     "iopub.status.idle": "2025-03-15T11:46:05.652711Z",
     "shell.execute_reply": "2025-03-15T11:46:05.651838Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.635064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Part 2: Data Balancing Function\n",
    "def balance_dataset(X_train, y_train, method='smote'):\n",
    "    \"\"\"\n",
    "    Balance the dataset using different techniques\n",
    "    \"\"\"\n",
    "    print(\"Class distribution before balancing:\")\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    \n",
    "    if method == 'smote':\n",
    "        sampler = SMOTE(random_state=42)\n",
    "    elif method == 'adasyn':\n",
    "        sampler = ADASYN(random_state=42)\n",
    "    elif method == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "    elif method == 'hybrid':\n",
    "        # Hybrid approach: undersample majority + oversample minority\n",
    "        # First undersample the majority class\n",
    "        rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "        X_temp, y_temp = rus.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Then oversample the minority class to achieve perfect balance\n",
    "        sampler = SMOTE(random_state=42)\n",
    "        X_balanced, y_balanced = sampler.fit_resample(X_temp, y_temp)\n",
    "        \n",
    "        print(\"Class distribution after hybrid balancing:\")\n",
    "        print(pd.Series(y_balanced).value_counts())\n",
    "        \n",
    "        return X_balanced, y_balanced\n",
    "    else:\n",
    "        print(\"No balancing applied\")\n",
    "        return X_train, y_train\n",
    "    \n",
    "    # Apply the selected sampling method\n",
    "    X_balanced, y_balanced = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"Class distribution after balancing:\")\n",
    "    print(pd.Series(y_balanced).value_counts())\n",
    "    \n",
    "    return X_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.653609Z",
     "iopub.status.busy": "2025-03-15T11:46:05.653396Z",
     "iopub.status.idle": "2025-03-15T11:46:05.666073Z",
     "shell.execute_reply": "2025-03-15T11:46:05.665260Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.653591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Part 3: Data Augmentation Function\n",
    "def augment_data(X, y, noise_level=0.05, n_samples=None):\n",
    "    \"\"\"\n",
    "    Augment data by adding Gaussian noise\n",
    "    \"\"\"\n",
    "    if n_samples is None:\n",
    "        n_samples = int(X.shape[0] * 0.3)  # Add 30% more samples by default\n",
    "    \n",
    "    # Create copies of existing samples with added noise\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    # Get class distribution\n",
    "    class_counts = Counter(y)\n",
    "    minority_class = min(class_counts, key=class_counts.get)\n",
    "    \n",
    "    # Focus augmentation on minority class for better balance\n",
    "    indices = np.where(y == minority_class)[0]\n",
    "    if len(indices) == 0:  # fallback if labels are not properly encoded\n",
    "        indices = np.random.choice(len(y), size=n_samples, replace=True)\n",
    "    else:\n",
    "        # Sample with replacement if we need more than available minority samples\n",
    "        indices = np.random.choice(indices, size=n_samples, replace=len(indices) < n_samples)\n",
    "    \n",
    "    for idx in indices:\n",
    "        # Get the original sample\n",
    "        sample = X[idx].copy()\n",
    "        \n",
    "        # Add Gaussian noise to each feature\n",
    "        noise = np.random.normal(0, noise_level, size=sample.shape)\n",
    "        augmented_sample = sample + noise * np.abs(sample)  # Scale noise by feature magnitude\n",
    "        \n",
    "        augmented_X.append(augmented_sample)\n",
    "        augmented_y.append(y[idx])\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_augmented = np.vstack([X, np.array(augmented_X)])\n",
    "    y_augmented = np.concatenate([y, np.array(augmented_y)])\n",
    "    \n",
    "    print(f\"Data augmented from {X.shape[0]} to {X_augmented.shape[0]} samples\")\n",
    "    \n",
    "    return X_augmented, y_augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.667174Z",
     "iopub.status.busy": "2025-03-15T11:46:05.666880Z",
     "iopub.status.idle": "2025-03-15T11:46:05.685146Z",
     "shell.execute_reply": "2025-03-15T11:46:05.684519Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.667142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Stacking Ensemble Functions\n",
    "# -------------------------------\n",
    "def create_base_models():\n",
    "    \"\"\"\n",
    "    Create a dictionary of diverse base models.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'rf': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'gbm': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        'svm': SVC(probability=True, random_state=42),\n",
    "        'lgbm': LGBMClassifier(\n",
    "                random_state=42,\n",
    "                min_child_samples=5,\n",
    "                min_split_gain=0.1,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "            ),\n",
    "        'xgb': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        'mlp': MLPClassifier(max_iter=1000, random_state=42)\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def build_stacking_ensemble(X_train, y_train,  voting_type='soft'):\n",
    "    \"\"\"\n",
    "    Build an ensemble using stacking or voting. (Only 'soft' and 'stacking' support predict_proba.)\n",
    "    \"\"\"\n",
    "    base_models = create_base_models()\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    meta_learner = LogisticRegression(random_state=42)\n",
    "    \n",
    "    if voting_type == 'stacking':\n",
    "        ensemble = StackingClassifier(\n",
    "            estimators=[(name, model) for name, model in base_models.items()],\n",
    "            final_estimator=meta_learner,\n",
    "            cv=cv,\n",
    "            stack_method='predict_proba'\n",
    "        )\n",
    "    else:\n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=[(name, model) for name, model in base_models.items()],\n",
    "            voting=voting_type  # Expecting 'soft' for probability estimates\n",
    "        )\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.686244Z",
     "iopub.status.busy": "2025-03-15T11:46:05.685967Z",
     "iopub.status.idle": "2025-03-15T11:46:05.705044Z",
     "shell.execute_reply": "2025-03-15T11:46:05.704234Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.686216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Main Pipeline Function\n",
    "# -------------------------------\n",
    "def run_ml_pipeline():\n",
    "    \"\"\"\n",
    "    Run the complete ML pipeline and evaluate using AUROC.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data()\n",
    "    \n",
    "    print(\"\\nSplitting data into train, validation, and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    \n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    X_train_processed, X_test_processed, feature_names, preprocessor = preprocess_data(X_train, X_test)\n",
    "    \n",
    "    print(\"\\nPerforming feature selection...\")\n",
    "    k = min(15, X_train_processed.shape[1])\n",
    "    print(\"Running SelectKBest...\")\n",
    "    selected_indices_kb, X_train_kb = select_k_best_features(X_train_processed, y_train, k=k)\n",
    "    X_test_kb = X_test_processed[:, selected_indices_kb]\n",
    "    \n",
    "    print(\"Running Recursive Feature Elimination...\")\n",
    "    selected_indices_rfe, X_train_rfe = recursive_feature_elimination(X_train_processed, y_train, n_features=k)\n",
    "    X_test_rfe = X_test_processed[:, selected_indices_rfe]\n",
    "    \n",
    "    try:\n",
    "        print(\"Running MRMR...\")\n",
    "        selected_indices_mrmr = mrmr_feature_selection(X_train_processed, y_train, k=k)\n",
    "        if selected_indices_mrmr is not None:\n",
    "            X_train_mrmr = X_train_processed[:, selected_indices_mrmr]\n",
    "            X_test_mrmr = X_test_processed[:, selected_indices_mrmr]\n",
    "        else:\n",
    "            raise Exception(\"MRMR returned None\")\n",
    "    except Exception as e:\n",
    "        print(f\"MRMR selection failed: {e}\")\n",
    "        print(\"Defaulting to SelectKBest results\")\n",
    "        X_train_mrmr, X_test_mrmr = X_train_kb, X_test_kb\n",
    "    \n",
    "    print(\"\\nEvaluating feature selection methods using RandomForestClassifier (AUROC)...\")\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_kb, y_train)\n",
    "    kb_metric = roc_auc_score(y_test, model.predict_proba(X_test_kb)[:,1])\n",
    "    print(f\"SelectKBest AUROC: {kb_metric:.4f}\")\n",
    "    \n",
    "    model.fit(X_train_rfe, y_train)\n",
    "    rfe_metric = roc_auc_score(y_test, model.predict_proba(X_test_rfe)[:,1])\n",
    "    print(f\"RFE AUROC: {rfe_metric:.4f}\")\n",
    "    \n",
    "    model.fit(X_train_mrmr, y_train)\n",
    "    mrmr_metric = roc_auc_score(y_test, model.predict_proba(X_test_mrmr)[:,1])\n",
    "    print(f\"MRMR AUROC: {mrmr_metric:.4f}\")\n",
    "    \n",
    "    fs_best_metric = max(kb_metric, rfe_metric, mrmr_metric)\n",
    "    if fs_best_metric == kb_metric:\n",
    "        print(\"SelectKBest performed best\")\n",
    "        X_train_selected, X_test_selected = X_train_kb, X_test_kb, X_test_kb\n",
    "        selected_indices = selected_indices_kb\n",
    "    elif fs_best_metric == rfe_metric:\n",
    "        print(\"RFE performed best\")\n",
    "        X_train_selected, X_test_selected = X_train_rfe, X_test_rfe\n",
    "        selected_indices = selected_indices_rfe\n",
    "    else:\n",
    "        print(\"MRMR performed best\")\n",
    "        X_train_selected, X_test_selected = X_train_mrmr, X_test_mrmr\n",
    "        selected_indices = selected_indices_mrmr\n",
    "    \n",
    "    if len(feature_names) > 0:\n",
    "        selected_features = feature_names[selected_indices]\n",
    "        print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    baseline_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    baseline_model.fit(X_train_processed, y_train)\n",
    "    baseline_metric = roc_auc_score(y_test, baseline_model.predict_proba(X_test_processed)[:,1])\n",
    "\n",
    "    print(\"Applying PCA feature extraction...\")\n",
    "    X_train_pca, X_test_pca, pca = apply_pca(X_train_processed, X_test_processed)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    pca_metric = roc_auc_score(y_test, model.predict_proba(X_test_pca)[:,1])\n",
    "    \n",
    "    final_max_metric = max(pca_metric, baseline_metric, fs_best_metric)\n",
    "    if fs_best_metric == final_max_metric:\n",
    "        print(\"Feature Selection Performed Better ...\")\n",
    "        X_train_final, X_test_final = X_train_selected, X_test_selected\n",
    "    elif pca_metric == final_max_metric:\n",
    "        print(\"Feature Extraction (PCA) Performed Better ...\")\n",
    "        X_train_final, X_test_final = X_train_pca, X_test_pca\n",
    "    else:\n",
    "        print(\"Feature Extraction and Selection didn't performed well ...\")\n",
    "        X_train_final, X_test_final = X_train_processed, X_test_processed\n",
    "\n",
    "    print(\"\\nChecking class balance...\")\n",
    "    class_counts = pd.Series(y_train).value_counts()\n",
    "    if len(class_counts) > 1:\n",
    "        imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "        if imbalance_ratio > 1.5:\n",
    "            print(f\"Dataset is imbalanced with ratio {imbalance_ratio:.2f}\")\n",
    "            print(\"Balancing dataset...\")\n",
    "            X_train_balanced, y_train_balanced = balance_dataset(X_train_final, y_train, method='hybrid')\n",
    "        else:\n",
    "            print(f\"Dataset is relatively balanced with ratio {imbalance_ratio:.2f}\")\n",
    "            X_train_balanced, y_train_balanced = X_train_final, y_train\n",
    "    else:\n",
    "        print(\"Warning: Only one class detected in training data\")\n",
    "        X_train_balanced, y_train_balanced = X_train_final, y_train\n",
    "    \n",
    "    print(\"\\nAugmenting training data...\")\n",
    "    X_train_augmented, y_train_augmented = augment_data(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    print(\"\\nBuilding stacking ensembles (using only 'soft' and 'stacking' for probability estimates)...\")\n",
    "    soft_ensemble = build_stacking_ensemble(X_train_augmented, y_train_augmented, voting_type='soft')\n",
    "    stacking_ensemble = build_stacking_ensemble(X_train_augmented, y_train_augmented, voting_type='stacking')\n",
    "    \n",
    "    print(\"\\nSelecting best ensemble model based on validation AUROC...\")\n",
    "    soft_result = soft_ensemble.predict_proba(X_test_final)\n",
    "    stacking_result = stacking_ensemble.predict_proba(X_test_final)\n",
    "\n",
    "    print(\"\\n\\nFinal Test Results:\")\n",
    "    soft_auroc = roc_auc_score(y_test, soft_result[:,1])\n",
    "    stacking_auroc = roc_auc_score(y_test, stacking_result[:,1])\n",
    "\n",
    "    print(f\"Soft Voting AUROC: {soft_auroc:.4f}\")\n",
    "    print(f\"Stacking Ensemble AUROC: {stacking_auroc:.4f}\")\n",
    "    \n",
    "    if stacking_auroc >= soft_auroc:\n",
    "        print(\"Stacking classifier performed best\")\n",
    "        final_ensemble = stacking_ensemble\n",
    "    else:\n",
    "        print(\"Soft voting ensemble performed best\")\n",
    "        final_ensemble = soft_ensemble\n",
    "    \n",
    "    # For reference, also compute F1 score (optional)\n",
    "    y_test_pred = final_ensemble.predict(X_test_final)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, pos_label='>50K' if isinstance(y_test.iloc[0], str) else 1)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Accuracy Score: {test_accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    # -------------------------------\n",
    "    # Confusion Matrix Plot Section\n",
    "    # -------------------------------\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=['<=50K', '>50K'], yticklabels=['<=50K', '>50K'])\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': final_ensemble,\n",
    "        'preprocessor': preprocessor,\n",
    "        'f1_score': test_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:46:05.706111Z",
     "iopub.status.busy": "2025-03-15T11:46:05.705808Z",
     "iopub.status.idle": "2025-03-15T11:46:49.029641Z",
     "shell.execute_reply": "2025-03-15T11:46:49.028693Z",
     "shell.execute_reply.started": "2025-03-15T11:46:05.706083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country   label  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country   label  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "\n",
      "Splitting data into train, validation, and test sets...\n",
      "Training set: 24129 samples\n",
      "Test set: 6033 samples\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Performing feature selection...\n",
      "Running SelectKBest...\n",
      "Running Recursive Feature Elimination...\n",
      "Running MRMR...\n",
      "\n",
      "Evaluating feature selection methods using RandomForestClassifier (AUROC)...\n",
      "SelectKBest AUROC: 0.8730\n",
      "RFE AUROC: 0.8938\n",
      "MRMR AUROC: 0.9010\n",
      "MRMR performed best\n",
      "Selected features: ['native_country_ Vietnam' 'education_ Preschool'\n",
      " 'native_country_ Columbia' 'education_ Masters' 'native_country_ Peru'\n",
      " 'education_ Doctorate' 'native_country_ France'\n",
      " 'native_country_ Trinadad&Tobago' 'workclass_ Local-gov'\n",
      " 'native_country_ Haiti' 'native_country_ Thailand'\n",
      " 'native_country_ Hungary' 'education_ 10th' 'relationship_ Husband'\n",
      " 'occupation_ Farming-fishing' 'education_ Bachelors'\n",
      " 'native_country_ Outlying-US(Guam-USVI-etc)' 'education_ Assoc-voc'\n",
      " 'native_country_ Portugal' 'native_country_ Scotland'\n",
      " 'native_country_ China' 'education_num' 'race_ Asian-Pac-Islander'\n",
      " 'education_ 12th' 'native_country_ Ecuador' 'workclass_ State-gov' 'age'\n",
      " 'education_ 5th-6th' 'native_country_ Guatemala' 'native_country_ South'\n",
      " 'marital_status_ Separated' 'native_country_ United-States'\n",
      " 'native_country_ Japan' 'occupation_ Transport-moving'\n",
      " 'native_country_ Iran' 'native_country_ Ireland' 'native_country_ India'\n",
      " 'native_country_ Hong' 'native_country_ Honduras'\n",
      " 'workclass_ Self-emp-not-inc' 'race_ Other' 'native_country_ Germany'\n",
      " 'relationship_ Wife' 'workclass_ Federal-gov' 'race_ Amer-Indian-Eskimo'\n",
      " 'workclass_ Self-emp-inc' 'native_country_ Poland'\n",
      " 'occupation_ Craft-repair' 'marital_status_ Widowed'\n",
      " 'native_country_ Puerto-Rico' 'native_country_ Taiwan'\n",
      " 'occupation_ Sales' 'marital_status_ Divorced' 'sex_ Male'\n",
      " 'relationship_ Own-child' 'occupation_ Prof-specialty'\n",
      " 'occupation_ Armed-Forces' 'education_ 11th' 'capital_loss'\n",
      " 'capital_gain' 'education_ 1st-4th' 'native_country_ Cuba' 'sex_ Female'\n",
      " 'hours_per_week' 'native_country_ Canada' 'education_ Assoc-acdm'\n",
      " 'education_ 7th-8th' 'marital_status_ Married-spouse-absent'\n",
      " 'education_ Some-college' 'marital_status_ Married-AF-spouse'\n",
      " 'marital_status_ Never-married' 'education_ 9th'\n",
      " 'native_country_ El-Salvador' 'occupation_ Tech-support'\n",
      " 'native_country_ Holand-Netherlands' 'native_country_ Cambodia'\n",
      " 'relationship_ Unmarried' 'native_country_ Nicaragua'\n",
      " 'marital_status_ Married-civ-spouse' 'workclass_ Without-pay'\n",
      " 'occupation_ Handlers-cleaners' 'relationship_ Not-in-family'\n",
      " 'relationship_ Other-relative' 'native_country_ Greece'\n",
      " 'education_ HS-grad' 'native_country_ Philippines' 'fnlwgt'\n",
      " 'workclass_ Private' 'native_country_ Jamaica' 'native_country_ England'\n",
      " 'native_country_ Mexico' 'occupation_ Other-service'\n",
      " 'native_country_ Italy' 'education_ Prof-school' 'native_country_ Laos'\n",
      " 'native_country_ Yugoslavia' 'occupation_ Exec-managerial'\n",
      " 'occupation_ Adm-clerical' 'occupation_ Priv-house-serv'\n",
      " 'occupation_ Machine-op-inspct' 'native_country_ Dominican-Republic'\n",
      " 'race_ Black' 'race_ White' 'occupation_ Protective-serv']\n",
      "Applying PCA feature extraction...\n",
      "Selected 31 components to explain 95.0% of variance\n",
      "Feature Selection Performed Better ...\n",
      "\n",
      "Checking class balance...\n",
      "Dataset is imbalanced with ratio 3.02\n",
      "Balancing dataset...\n",
      "Class distribution before balancing:\n",
      "label\n",
      "<=50K    18123\n",
      ">50K      6006\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ssd-KmRqJrsb-py3.13\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\amir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ssd-KmRqJrsb-py3.13\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\amir\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amir\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amir\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after hybrid balancing:\n",
      "label\n",
      "<=50K    12012\n",
      ">50K     12012\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Augmenting training data...\n",
      "Data augmented from 24024 to 31231 samples\n",
      "\n",
      "Building stacking ensembles (using only 'soft' and 'stacking' for probability estimates)...\n"
     ]
    }
   ],
   "source": [
    "results = run_ml_pipeline()\n",
    "print(\"\\nMachine Learning Pipeline Completed Successfully\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 222,
     "sourceId": 472,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ssd-KmRqJrsb-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
